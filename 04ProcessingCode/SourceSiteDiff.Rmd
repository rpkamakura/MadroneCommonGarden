---
title: "SiteDiffSource"
author: "Renata Poulton Kamakura"
date: "January 28, 2020"
output: pdf_document
---

```{r setup, include=FALSE}
source("Madrone4/Madrone3/Data Analysis/PerSiteAnalys3.R")
source("Madrone4/Madrone3/Data Analysis/RegressionFuncs2.R")
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization

##Common Garden Site Names and years of data collection
sites <- c("PuyallupHill","PuyallupValley", "Starker", "Sprague")
years <- c(12, 13, 14, 15)

#Read in raw site data
pertfiles <- list("Madrone4/Madrone3/Basic Datasets/PHFulldata4.csv", "Madrone4/Madrone3/Basic Datasets/PVFulldata4.csv",
                  "Madrone4/Madrone3/Basic Datasets/SFFulldata4.csv", "Madrone4/Madrone3/Basic Datasets/SOFulldata4.csv")

sitesdata <- lapply(pertfiles,read.csv)
names(sitesdata) <- sites

#Get Growth and Dieback Data
Growth = IndivHeights_byTree(sitesdata, years, sites)
totGRData <- rbind(Growth) #combine all sites into one file

##Get the Mortality Data
condata <- IndivCond_final(sitesdata, sites)
totMortData <- rbind(condata) #combine all sites into one file

##Families with ecoregions
ecoregdat <- read.csv("Madrone4/Madrone3/Basic Datasets/EcoregionData.csv")
names(ecoregdat)[2] <- "Family" 

#Data with different Distances
DistData <- read.csv("Madrone4/Madrone3/Distance Data/DistancesDir2.csv")
names(DistData)[1] <- "Family" 
  
#Data with climatic variables
ClimData <- read.csv("Madrone4/Madrone3/Basic Datasets/LocandClim_sa.csv")

#Merge the datasets together
Fulldata <- merge(ecoregdat, ClimData, by ="Family")
#Fulldata <- merge(Fulldata, DistData, by ="Family")
Fulldata2 <- merge(Fulldata, DistData, by="Family")
```

## Number of Centers to Use


```{r}
for (site in sites){ #iterate through each common garden site
  
  ##Get the site-specific information to adapt the later analyses
  if (site == "PuyallupHill"){
    #distcol <- match("PH.Dist", names(Fulldata))
    #elevdistcol <- match("PH.ElevDist", names(Fulldata))
    eco <- "PULO"
    st <- "PH"
    
  } else if (site == "PuyallupValley"){
    #distcol <- match("PV.Dist", names(Fulldata))
    eco <- "PULO"
    st <- "PV"
    
  } else if (site == "Starker") {
    #distcol <- match("SF.Dist", names(Fulldata))
    #elevdistcol <- match("SF.ElevDist", names(Fulldata))
    eco <- "WIVA"
    st <- "SF"
    
  } else if (site == "Sprague"){
    #distcol <- match("SO.Dist", names(Fulldata))
    #elevdistcol <- match("SO.ElevDist", names(Fulldata))
    eco <- "KLMT"
    st <- "SO"
  }
  
  ##Filter by Ecoregion
  sameeco_dat <- Fulldata[Fulldata$EcoregionShort == eco,]
  
  #Columns to use for analyses
  all_cols <- c(1, 6, 7, 8, 11, 13, 15)
  
  #Only the useful columns
  rel_data <- sameeco_dat[, all_cols]
  
  ##The values for each site to use to calculate distances
  stclim_ind <- match(site, ClimData$Family) #common garden site col
  
  st_bFFP <- ClimData$bFFP[stclim_ind]
  st_MSP <- ClimData$MSP[stclim_ind]
  st_Slo <- ClimData$Slope[stclim_ind]
  st_Lat <- ClimData$Latitude[stclim_ind]
  st_Long <- ClimData$Longitude[stclim_ind]
  st_Elev <- ClimData$Elevation[stclim_ind]
  
  Site_rel_data <- as.data.frame(matrix(c(st, st_Lat, st_Long, st_Elev, st_bFFP, st_MSP, st_Slo), nrow=1, ncol=7)) 
  names(Site_rel_data) <- names(rel_data)
  
  all_rel_data <- rbind(rel_data, Site_rel_data)
  
  rownames(all_rel_data) <- all_rel_data[,1]
  all_rel_data <- all_rel_data[,2:7] 
  all_rel_data <- sapply(all_rel_data, as.numeric)
  
  ##rescaling so you can compare across
  all_rel_data<- scale(all_rel_data) 
  
  ##Pick the number of clusters
  sil <- fviz_nbclust(all_rel_data, kmeans, method = "silhouette", k.max = length(all_rel_data[,1])/2) 
  #For more info: https://uc-r.github.io/kmeans_clustering
  
  print(paste("Cluster analyses for the closest families at", site))
  print(sil)
  
  #####For the ones that are least similar##########################################
  
  ##Filter by Ecoregion
  diffeco_dat <- Fulldata[Fulldata$EcoregionShort != eco,]
  
  #Columns to use for analyses
  all_cols <- c(1, 6, 7, 8, 11, 13, 15)
  
  #Only the useful columns
  diff_data <- diffeco_dat[, all_cols]
  
  ##combine site with diff ones
  all_diff_data <- rbind(diff_data, Site_rel_data)
  
  #Renaming
  rownames(all_diff_data) <- all_diff_data[,1]
  all_diff_data <- all_diff_data[,2:7]
  all_diff_data <- sapply(all_diff_data, as.numeric)
  
  ##rescaling so you can compare across
  all_diff_data<- scale(all_diff_data) 
  
  ##Pick the number of clusters
  sil_diff <- fviz_nbclust(all_diff_data, kmeans, method = "silhouette", k.max = length(all_diff_data[,1])/2) 
  #For more info: https://uc-r.github.io/kmeans_clustering
  
  print(paste("Cluster analyses for the more different families at", site))
  print(sil_diff)
  
}
```


############################
PH
same: 7 K-means
diff: 40 k-means
PV
same: 7
diff: 40
SF
same: 7 #can only do 5 for sake of clustering
diff: 36
SO
same: 3
diff: 40
############################

```{r}
Dist1 <- function(x, y){
   (x - y)^2
  }

Dist2 <- function(x){
  sqrt( sum (x))
}
```

##Actual k-means


```{r}
#Creating the things to store the results
sim_fams <- list()
diff_fams <- list()


#Actually running the k-means thing
for (site in sites){ #iterate through each common garden site
  
  ##Get the site-specific information to adapt the later analyses
  if (site == "PuyallupHill"){
    #distcol <- match("PH.Dist", names(Fulldata))
    #elevdistcol <- match("PH.ElevDist", names(Fulldata))
    eco <- "PULO"
    st <- "PH"
    sim_cent <- 7
    diff_cent <- 40
    
  } else if (site == "PuyallupValley"){
    #distcol <- match("PV.Dist", names(Fulldata))
    eco <- "PULO"
    st <- "PV"
    sim_cent <- 7
    diff_cent <- 40
    
  } else if (site == "Starker") {
    #distcol <- match("SF.Dist", names(Fulldata))
    #elevdistcol <- match("SF.ElevDist", names(Fulldata))
    eco <- "WIVA"
    st <- "SF"
    sim_cent <- 7
    diff_cent <- 36
    
  } else if (site == "Sprague"){
    #distcol <- match("SO.Dist", names(Fulldata))
    #elevdistcol <- match("SO.ElevDist", names(Fulldata))
    eco <- "KLMT"
    st <- "SO"
    sim_cent <- 3
    diff_cent <- 40
  }
  
  ##Filter by Ecoregion
  sameeco_dat <- Fulldata[Fulldata$EcoregionShort == eco,]
  
  #Columns to use for analyses
  all_cols <- c(1, 6, 7, 8, 11, 13, 15)
  
  #Only the useful columns
  rel_data <- sameeco_dat[, all_cols]
  
  ##The values for each site to use to calculate distances
  stclim_ind <- match(site, ClimData$Family) #common garden site col
  
  st_bFFP <- ClimData$bFFP[stclim_ind]
  st_MSP <- ClimData$MSP[stclim_ind]
  st_Slo <- ClimData$Slope[stclim_ind]
  st_Lat <- ClimData$Latitude[stclim_ind]
  st_Long <- ClimData$Longitude[stclim_ind]
  st_Elev <- ClimData$Elevation[stclim_ind]
  
  Site_rel_data <- as.data.frame(matrix(c(st, st_Lat, st_Long, st_Elev, st_bFFP, st_MSP, st_Slo), 
                                        nrow=1, ncol=7))
  names(Site_rel_data) <- names(rel_data)
  
  all_rel_data <- rbind(rel_data, Site_rel_data)
  
  rw_names <- all_rel_data[,1]
  all_rel_data <- all_rel_data[,2:7]
  all_rel_data <- sapply(all_rel_data, as.numeric)
  rownames(all_rel_data) <- rw_names
  
  ##rescaling so you can compare across
  all_rel_data<- scale(all_rel_data)  
  
  sim_k_means <- kmeans(all_rel_data, centers = sim_cent, nstart = 25) 
  clusters <- sim_k_means$cluster 
  st_cluster <- clusters[length(clusters)]
  sim_grp <- rw_names[clusters==st_cluster]
  
  if(length(sim_grp) == 1){ #If the site ends up all by itself
    t_cluster <- clusters[length(clusters)]
    st_center <- sim_k_means$centers[st_cluster,]
    other_centers <- sim_k_means$centers[-st_cluster,]
    differences <- abs(other_centers[1,] - st_center)
    
    #Find the distance from the center to all the other centers
    diff_sq <- apply(other_centers, 1, Dist1, st_center)
    center_dist <- apply(diff_sq, 2, Dist2)
    
    #Find the center that is the furthest from the center with the site
    min_diff <- names(center_dist[center_dist == min(center_dist)])
    sim_grp <- rw_names[clusters==min_diff]
  }
  
  #####For the ones that are least similar##########################################
  
  ##Filter by Ecoregion
  diffeco_dat <- Fulldata[Fulldata$EcoregionShort != eco,]
  
  #Columns to use for analyses
  all_cols <- c(1, 6, 7, 8, 11, 13, 15)
  
  #Only the useful columns
  diff_data <- diffeco_dat[, all_cols]
  
  ##combine site with diff ones
  all_diff_data <- rbind(diff_data, Site_rel_data)
  
  #Renaming
  rw_names  <- all_diff_data[,1]
  all_diff_data <- all_diff_data[,2:7]
  all_diff_data <- sapply(all_diff_data, as.numeric)
  rownames(all_diff_data) <- rw_names
  
  ##rescaling so you can compare across
  all_diff_data<- scale(all_diff_data) 
  
  diff_k_means <- kmeans(all_diff_data, centers = diff_cent, nstart = 25)
  
  ##NEED TO ADJUST THIS PART#####
  
  clusters <- diff_k_means$cluster 
  st_cluster <- clusters[length(clusters)]
  st_center <- diff_k_means$centers[st_cluster,]
  other_centers <- diff_k_means$centers[-st_cluster,]
  differences <- abs(other_centers[1,] - st_center)
  
  #Find the distance from the center to all the other centers
  diff_sq <- apply(other_centers, 1, Dist1, st_center)
  center_dist <- apply(diff_sq, 2, Dist2)
  
  #Find the center that is the furthest from the center with the site
  most_diff <- names(center_dist[center_dist == max(center_dist)])
  diff_grp <- rw_names[clusters==most_diff]
  
  ########Store the results
  if (site == "PuyallupHill"){
    sim_fams[[1]] <- sim_grp
    diff_fams[[1]] <- diff_grp
    
  } else if (site == "PuyallupValley"){
    sim_fams[[2]] <- sim_grp
    diff_fams[[2]] <- diff_grp
    
  } else if (site == "Starker") {
    sim_fams[[3]] <- sim_grp
    diff_fams[[3]] <- diff_grp
    
  } else if (site == "Sprague"){
    sim_fams[[4]] <- sim_grp
    diff_fams[[4]] <- diff_grp
  }
  
}

names(sim_fams) <- sites
names(diff_fams) <- sites
```



The issue here is that you also want the ones that "perform well" across the board. How would you decide which ones those are? 
- ANOVA? 
- clustering of growth, mortality, and dieback and pick the ones that are near something? 
  - you could make an artificially high point that is the max (or min) of each variable at each site and see what clusters with that? Then you could see if there are things that consistently cluster with it
  - lowest growth, highest mortality and then vice versa? 
  - in effect, repeating the above but with the Growth and condata and instead of add the site at the end, you add your artificial point
  
  
##Outliers

alternatively, use the models you built and look at all the errors for each family
could use a histogram or something to see where potential outliers could be
identify those, and look to see what families they are

Problem with that is that the outliers could mask the importance of other variables
would have to assume that the model is correct to begin with
- I think you just have to do that. 
- find the families with the highest MAE, then re-run the analyses without them
  - what is a high MAE? Probs going to just have to histogram/boxplot it and see if there are any that are really out there (past 1.5*IQ)?
  
The code below is a solid start, but you need to figure out wtf you're doing with the outliers. HOw do you want those stored? Do you want to know the direction of the outlier (positive or negative)? How will you label them. ETc. 
  
```{r}
paramlist <- c("Ecoregion", "Dist", "Slope", "Aspect", "ElevDist", "bFFP", "MSP")

functype <- c("E", "L", "Q", "Q", "Q", "Q", "Q", "Q")
func_num <- 1:length(paramlist)

sts_short <- c("PH", "PV", "SF", "SO")

##Need to change this
#regdata <- lapply(list("Madrone4/Madrone3/Data Analysis/TotGrowth _BestMultReg5.csv","Madrone4/Madrone3/Data Analysis/AmntDieback _BestMultReg5.csv", "Madrone4/Madrone3/Data Analysis/MortalityBestMultReg8.csv"), read.csv)

regdata <- read.csv("Madrone4/Madrone3/Data Analysis/FinalModels_performance.csv")

dvar <- 0 #just to keep track of which one you're on 

outlier_colnms <- c("Site", "Dvar", "Type", "Names")
outlier_mat <- as.data.frame(matrix(0, nrow = 2*4*3, ncol = length(outlier_colnms)))
names(outlier_mat) <- outlier_colnms
mat_iter <- 0

dvar_nms <- c("Growth", "Dieback", "Mortality")


for (DepVar in dvar_nms) { #For each response variable 
  dvar <- dvar + 1
  
  n <- 4 #the number of sites for Growth Rate, Dieback, and Mortality 
  paramlist <- c("Ecoregion", "Dist", "Slope", "Aspect", "ElevDist", "bFFP", "MSP")
  
  #######################################################################
  for (grp in 1:n){ ##the groupings, either by site or by phen for phenology 
    
    if (dvar == 1 || dvar == 2){ #growth rate or dieback
      df <- Growth[[grp]]
      df <- df[complete.cases(df), ] #get rid of the NAs basically
      df_class <- df$Source
      binomial = FALSE

      grp_nm <- as.vector(df$Site[1])
      
      if (dvar == 1){
        grp_col <- match("TotGrowth", colnames(df)) 
        RandVar <- match("Block", colnames(df)) #random variable
        
      } else {
        
        grp_col <- match("AmntDieback", colnames(df))
        RandVar <- match("Block", colnames(df)) #random variable
      
      }
      
      
    } else if (dvar == 3){ #Mortality 
      
      
      df <- condata[[grp]]
      df <- df[complete.cases(df), ] #get rid of the NAs basically
      df_class <- df$Source
      binomial = TRUE

      st <- df$Site[1]
      st_ind <- match(st, sites)
      grp_nm <- sts_short[st_ind]
      
      grp_col <- match("PercDead", colnames(df)) 
      RandVar <- match("Block", colnames(df)) #random variable
      ntrials <- match("Total", colnames(df))
      
      
    } ## end of dataframe and column delineation loop 
  
    pert_regs <- regdata[(as.vector(regdata$Site) == as.character(grp_nm)),] #find the regressions for that site
    depvar_reg <- pert_regs[pert_regs$DepVar == DepVar,]

    ######################################################################
    
      indep_vars <- unlist(strsplit(as.vector(depvar_reg$Model), "_")) #split the variables up 
      indep_ind <- match(indep_vars, colnames(df)) #get the indexes for the independent variables
      indep_func_ind <- match(indep_vars, paramlist) #get the index for their function types
      
      if (dvar ==3){ ##for the mortality data
      
        reg_res1 <- MultReg3(df, indep_ind, grp_col, RandVar, binomial, priorw = ntrials)
        #reg_results
        
        res1_df <- reg_res1[[1]]
        res1_obj <- reg_res1[[2]]
        
        ##should be able to use the function predict, but you have to create the right format of df
        error_df <- as.data.frame(matrix(0, nrow = length(df[,1]), ncol = length(res1_df)))
        names(error_df) <- names(res1_df)

        for (c in 1:length(res1_df)){
          
          if (c == 1){
            error_df[,c] <- df[,grp_col] #Dependent Variable
            
          } else if (c != length (res1_df)){
            
            if( c == (length(res1_df)-1)){
              error_df[,c] <- df[,RandVar] #Random Variable
            } else {
              error_df[,c] <- df[,indep_ind[(c-1)]] #Independent Variables
            }
            
          } else {
            error_df[,c] <- df[,ntrials]
          }
        }
        
        
      } else { ##for everything except the Phenology ones
        types <- functype[indep_func_ind] #get the function types
        
        ##Add the names of/number of independent variables to the corresponding lists
   
        reg_res1 <- MultReg2(df, indep_ind, grp_col, types, RandVar)
        
        res1_df <- reg_res1[[1]]
        res1_obj <- reg_res1[[2]]
        
        ##should be able to use the function predict, but you have to create the right format of df
        error_df <- as.data.frame(matrix(0, nrow = length(df[,1]), ncol = length(res1_df)))
        names(error_df) <- names(res1_df)
        
        sq <- FALSE
        test_ind <- 1

        for (c in 1:length(res1_df)){
          
          if (c == 1){
            error_df[,c] <- df[,grp_col] #Dependent Variable
            
          } else if (c == length(res1_df)) {
            
            error_df[,c] <- df[,RandVar] #Random Variable
            
          } else if (types[test_ind] == "E" || types[test_ind] == "L") {
            error_df[,c] <- df[,indep_ind[(c-1)]] #Independent Variables
            test_ind <- test_ind + 1
            
          } else { #not at the end and not a linear term (so the quadratic terms)
            
            if (sq) { #if it is the square of a value
              
              error_df[,c] <- (df[,indep_ind[(test_ind)]])^2 #Independent Variable Squared
              sq <- FALSE
              
              if (test_ind < length(types)){
                test_ind <- test_ind + 1
              }
              
              } else {
              error_df[,c] <- df[,indep_ind[(test_ind)]] #Independent Variables
              sq <- TRUE
            }
            
          }
          
        }
          
      } #end of gr, dbk, mort if statement
     
      ##Figure out which ones are "outliers", as in 1.5*IQR outside of the lower or upper quarts
      predictions <- as.vector(predict(res1_obj, error_df))
      
      iqr <- IQR(df[,grp_col] - predictions) #find the IQR, which you use to find the outliers
      quants <- quantile(df[,grp_col] - predictions)
      outliers_low <- as.vector(df[(df[,grp_col] - predictions < 
                                                   (as.vector(quants[2]) - 1.5*iqr)), ])
      outliers_high <- as.vector(df[(df[,grp_col] - predictions > 
                                                   (as.vector(quants[2]) + 1.5*iqr)), ])
      
      ##Figure out which families are really just all over the place
      remove <- outliers_low$Family[outliers_low$Family %in% outliers_high$Family]
      
      outliers_low <- outliers_low[!(outliers_low$Family %in% remove),]
      outliers_high <- outliers_high[!(outliers_high$Family %in% remove),]
      
      
      #Pare it down to only the ones with over 50% outliers
      unique_outlow <- unique(outliers_low$Family)
      unique_outhigh <- unique(outliers_high$Family)
      
      fam_freq <- as.data.frame(table(df$Family))
      fam_lowfreq <- as.data.frame(table(outliers_low$Family))
      fam_highfreq <- as.data.frame(table(outliers_high$Family))
      
      percent_low <- fam_lowfreq$Freq/fam_freq$Freq
      percent_high <- fam_highfreq$Freq/fam_freq$Freq
      
      half_low <- na.omit(fam_lowfreq$Var1[percent_low >= 0.33])
      half_high <- na.omit(fam_highfreq$Var1[percent_high >= 0.33])
      
      outhalf_low <- outliers_low[outliers_low$Family %in% half_low, ]
      outhalf_high <- outliers_high[outliers_high$Family %in% half_high, ]
      
      #Lower
      if (dim(outhalf_low)[1] > 0){
        low_nms <- paste(unique(as.vector(outhalf_low$Family)), collapse= "_") #Get their names concatenated together
        mat_iter <- mat_iter + 1
        outlier_mat[mat_iter, ] <- c(grp_nm, DepVar, "Low", low_nms)
      }

      #Upper
      if (dim(outhalf_high)[1] > 0){
        high_nms <- paste(unique(as.vector(outhalf_high$Family)), collapse= "_") #Get their names concatenated together
        mat_iter <- mat_iter + 1
        outlier_mat[mat_iter, ] <- c(grp_nm, DepVar, "High", high_nms)
      }
        
        
  } ## end of site/phenological loop 
  
  
}   


```
Growth:


high_outs <- c("DBK_BK3_BL1_BL2_BL3_CR2_GA3_HC1_HP1_LA5_LA8_SA5_SA7_SA8_SN1_SN2_SR2_PMT_WV2")


##Summary Data
Need to add the outliers to these summaries
```{r}
##From the outliers matrix
outhi_DBK <- c("BK3","BL1","BL2","BL3","CR2","GA3","HC1","HP1","LA5","LA8","SA5","SA7","SA8","SN1","SN2","SR2","PMT","WV2")
outhi_PMT <- c("WV2")

high_outs <- c("DBK_BK3_BL1_BL2_BL3_CR2_GA3_HC1_HP1_LA5_LA8_SA5_SA7_SA8_SN1_SN2_SR2_PMT_WV2")


Numrws <- 4*3
colNms <- c("Site", "Group", "Growth", "Dieback", "Mortality", "Families")
SummaryMat <- as.data.frame(matrix (0, nrow = Numrws, ncol = length(colNms)))
names(SummaryMat) <- colNms
rw_iter <- 0

#You may want to check the name rather than assuming the order is the same
for (site in 1:length(sites)){
  
  rw_iter <- rw_iter + 1
  #Get the relevant indices 
  st <- sites[[site]]
  sims <- sim_fams[[site]]
  diffs <- diff_fams[[site]]
  
  st_growth <- Growth[[site]]
  st_mort <- condata[[site]]
  
  #Growth Rate
  sim_avgGR <- mean(na.omit(st_growth$TotGrowth[st_growth$Family %in% sims])) #average growth over all similar families
  diff_avgGR <- mean(na.omit(st_growth$TotGrowth[st_growth$Family %in% diffs])) #average growth over all different families
  outhi_avgGR <- NA
  
  
  
  #Dieback 
  sim_avgDBK <- mean(na.omit(st_growth$AmntDieback[st_growth$Family %in% sims])) #average dieback over all similar families
  diff_avgDBK <- mean(na.omit(st_growth$AmntDieback[st_growth$Family %in% diffs])) #average dieback over all different families
  outhi_avgDBK <- mean(na.omit(st_growth$AmntDieback[st_growth$Family %in% outhi_DBK]))
  
  
  
  #Mortality
  sim_avgPMT <- mean(na.omit(st_mort$PercDead[st_mort$Family %in% sims])) #average mortality over all similar families
  diff_avgPMT <- mean(na.omit(st_mort$PercDead[st_mort$Family %in% diffs])) #average mortality over all different families
  outhi_avgPMT <- mean(na.omit(st_mort$PercDead[st_mort$Family %in% outhi_PMT]))
  
  
  ##Similar
  SummaryMat[rw_iter, ] <- c(as.vector(st_growth$Site[1]), "Similar", sim_avgGR, sim_avgDBK, sim_avgPMT, paste(sims, collapse= "_"))
  
  rw_iter <- rw_iter + 1
  
  #Different
  SummaryMat[rw_iter, ] <- c(as.vector(st_growth$Site[1]), "Different", diff_avgGR, diff_avgDBK, diff_avgPMT, paste(diffs, collapse= "_"))
  
  rw_iter <- rw_iter + 1
  
  #High Outliers
  
  SummaryMat[rw_iter, ] <- c(as.vector(st_growth$Site[1]), "HighOutliers", outhi_avgGR, outhi_avgDBK, outhi_avgPMT, high_outs)
  
  rw_iter <- rw_iter + 1
  
}

write.csv(SummaryMat, "summarymatrix.csv")

```



##Phenology and growth, mortality, dieback

Should be able to do a simple regression, though you can't be sure that it'll be linear
  can do diff from the local and turn it into something linear? Simpler
  
```{r}
library(MuMIn) #for the r2 values

phen_dat <- read.csv("Madrone4/Madrone3/Data Analysis/SF_Phen_AlldataRaw2.csv") #read in the phenology data

#change Name to Family for the sake of consistency
nm_col <- match("Name", names(phen_dat))
names(phen_dat)[nm_col] <- "Family"
ctrl <- lmeControl(opt='optim')

n_rows <- 3*4 #variables x sites
col_nms <- c("Site", "DepVar", "SqTerm", "LinTerm", "r2")
n_cols <- length(col_nms)

Corr_mat <- as.data.frame(matrix(0, nrow = n_rows, ncol = n_cols))
names(Corr_mat) <- col_nms
matrow_ind <- 0

for (st in 1:length(sites)){
  st_nm <- sts_short[st] #short code name for each cg site
  
  sims <- sim_fams[[st]] ##families flags as similar
  #diffs <- diff_fams[[site]] ##Fams flagged as different
  
  st_growth <- Growth[[st]] #growth + dbk data
  st_mort <- condata[[st]] #mortality data
  
  sims_phen <- mean(phen_dat$Bud.Elongating[phen_dat$Family %in% sims]) #avg BEL for similar fams
  
  phen_dat$BEL_Diff <- phen_dat$Bud.Elongating - sims_phen
  avg_byfam <- aggregate(BEL_Diff ~ Family, phen_dat, mean )
  avg_byfam$BEL_Diff2 <- (avg_byfam$BEL_Diff)^2 #for quadratic relationship
  
  #add the phenology data
  st_growth <- merge(st_growth, avg_byfam, by="Family")
  st_mort <- merge(st_mort, avg_byfam, by="Family")
  
  #Growth
  GR_reg <- lme(TotGrowth ~ BEL_Diff2 + BEL_Diff, data = st_growth, random = ~1|Block, na.action = na.omit, control = ctrl, method="ML")
  
  #Dieback
  DBK_reg <- lme(AmntDieback ~ BEL_Diff2 + BEL_Diff, data = st_growth, random = ~1|Block, na.action = na.omit, control = ctrl, method="ML")
  
  #Mortality
  mort_reg <- glmer(PercDead ~ BEL_Diff2 + BEL_Diff + (1|Block), data = st_mort,family="binomial", control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=2e4)), weights = Total)
  
  print(paste("Correlation Results for", sites[st]))
  
  #Growth
  gr_sum <- summary(GR_reg)
  gr_r2 <- r.squaredGLMM(GR_reg)
  
  matrow_ind <- matrow_ind + 1
  Corr_mat[matrow_ind, ] <- c(st_nm, "Growth", as.vector(gr_sum$coefficients$fixed[2]), 
                              as.vector(gr_sum$coefficients$fixed[3]), gr_r2[1])

  #Dieback
  dbk_sum <- summary(DBK_reg)
  dbk_r2 <- r.squaredGLMM(DBK_reg) 
  
  matrow_ind <- matrow_ind + 1
  Corr_mat[matrow_ind, ] <- c(st_nm, "Dieback", as.vector(dbk_sum$coefficients$fixed[2]), 
                              as.vector(dbk_sum$coefficients$fixed[3]), dbk_r2[1])

  #Mortality
  mort_sum <- summary(mort_reg)
  mort_r2 <- r.squaredGLMM(mort_reg)
  
  matrow_ind <- matrow_ind + 1
  Corr_mat[matrow_ind, ] <- c(st_nm, "Mortality", as.vector(mort_sum$coefficients[2,1]), 
                              as.vector(mort_sum$coefficients[3,1]), mort_r2[1])
  
  
  #To visually inspect
  plot(TotGrowth ~ BEL_Diff, data = st_growth)
  plot(AmntDieback ~ BEL_Diff, data = st_growth)
  plot(PercDead ~ BEL_Diff, data = st_mort)
  
  
  
}

write.csv(Corr_mat, "PhenvsPerfCorrs.csv")

```

##Mortality and Growth
```{r}
matrow_ind <- 0

n_rows <- 1*4 #variables x sites
col_nms <- c("Site", "DepVar", "Coeff", "r2")
n_cols <- length(col_nms)

Corr_mat <- as.data.frame(matrix(0, nrow = n_rows, ncol = n_cols))
names(Corr_mat) <- col_nms

for (st in 1:length(sites)){
  st_nm <- sts_short[st]
  st_growth <- Growth[[st]] #growth + dbk data
  st_mort <- condata[[st]] #mortality data
  
  avg_byfamblock <- aggregate(TotGrowth ~ Family + Block, st_growth, mean )
  
  st_grmort <- merge(st_mort, avg_byfamblock, by= c("Family", "Block"))
  
  mort_reg <- glmer(PercDead ~ TotGrowth + (1|Block), data = st_grmort, family="binomial", control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=2e4)), weights = Total)
  
  print(paste("Correlation Results for", sites[st]))
  
  mort_sum <- summary(mort_reg)
  mort_r2 <- r.squaredGLMM(mort_reg)
  
  matrow_ind <- matrow_ind + 1
  Corr_mat[matrow_ind, ] <- c(st_nm, "Mortality", as.vector(mort_sum$coefficients[2,1]), 
                              mort_r2[1])
  
  
  
}

print(Corr_mat)

```



##Extra Code that Might be Useful
```{r}
#  ##For the low and high outliers
#   if ("Growth" %in% out_low$Dvar){
#     
#     fam_nms <- strsplit(out_low$Names[out_low$Dvar == "Growth"], split="_")
#     outlw_avgGR <- mean(na.omit(st_growth$TotGrowth[st_growth$Family %in% fam_nms[[1]]]))
#     
#   } else {
#     outlw_avgGR <- NA
#   }
#   
#   if ("Growth" %in% out_high$Dvar){
#     
#     fam_nms <- strsplit(out_high$Names[out_high$Dvar == "Growth"], split="_")
#     outhi_avgGR <- mean(na.omit(st_growth$TotGrowth[st_growth$Family %in% fam_nms[[1]]]))
#   } else {
#     outhi_avgGR <- NA
#   }
# 
# ##For the low and high outliers
#   if ("Dieback" %in% out_low$Dvar){
#     
#     fam_nms <- strsplit(out_low$Names[out_low$Dvar == "Dieback"], split="_")
#     outlw_avgDBK <- mean(na.omit(st_growth$AmntDieback[st_growth$Family %in% fam_nms[[1]]]))
#     
#   } else {
#     outlw_avgDBK <- NA
#   }
#   
#   if ("Dieback" %in% out_high$Dvar){
#     
#     fam_nms <- strsplit(out_high$Names[out_high$Dvar == "Dieback"], split="_")
#     outhi_avgDBK <- mean(na.omit(st_growth$AmntDieback[st_growth$Family %in% fam_nms[[1]]]))
#   } else {
#     outhi_avgDBK <- NA
#   }
# 
# ##For the low and high outliers
#   if ("Mortality" %in% out_low$Dvar){
#     
#     fam_nms <- strsplit(out_low$Names[out_low$Dvar == "Mortality"], split="_")
#     outlw_avgPMT <- mean(na.omit(st_mort$PercDead[st_mort$Family %in% fam_nms[[1]]]))
#     
#   } else {
#     outlw_avgPMT <- NA
#   }
#   
#   if ("Mortality" %in% out_high$Dvar){
#     
#     fam_nms <- strsplit(out_high$Names[out_high$Dvar == "Mortality"], split="_")
#     outhi_avgPMT <- mean(na.omit(st_mort$PercDead[st_mort$Family %in% fam_nms[[1]]]))
#   } else {
#     outhi_avgPMT <- NA
#   }

```
