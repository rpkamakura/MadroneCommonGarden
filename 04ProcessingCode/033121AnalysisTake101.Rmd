---
title: "R Notebook"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(plyr)
library(dplyr)
library(MASS)
library(MuMIn)
library(caret)
#library(ModelMetrics) #for brier score
source("032521PerSiteAnalys.R")
source("032521RegressionFuncs.R")

setwd("C:/Users/rep31/Desktop/Madrone/Madrone5/Madrone3") #easier directory to work from

options(stringsAsFactors = FALSE)

#Names
years <- c(12, 13, 14, 15)
#years <- c(14,15)
sites <- c("PuyallupValley", "PuyallupHill", "Starker", "Sprague")

##Get the full data files
pertfiles <- list("./Basic Datasets/033121PVFulldata.csv", "./Basic Datasets/033121PHFulldata.csv",  "./Basic Datasets/033121SFFulldata.csv", "./Basic Datasets/033121SOFulldata.csv")
sitesdata <- lapply(pertfiles,read.csv)
names(sitesdata) <- sites

##Phenology data
PhenData <- read.csv("./033121SF_Phen_AlldataRaw.csv")

##Find the list of the best models for each variable 
regdata <- lapply(list("./Data Analysis/033121PhenBestMultReg.csv", "./Data Analysis/040121_TotGrowth_BestMultReg.csv","./Data Analysis/040121_AmntDieback_BestMultReg.csv", "./Data Analysis/033121MortalityBestMultReg.csv"), read.csv)

#regdata <- lapply(list("./Data Analysis/033121PhenBestMultReg.csv","./Data Analysis/040121_TotGrowth_BestMultReg14to15.csv","./Data Analysis/040121_AmntDieback_BestMultReg14to15.csv", "./Data Analysis/033121MortalityBestMultReg14to15.csv"), read.csv)

#regdata <- lapply(list("./Data Analysis/033121PhenBestMultReg.csv","./Data Analysis/040121_TotGrowth_BestMultReg12to13.csv","./Data Analysis/040121_AmntDieback_BestMultReg12to13.csv", "./Data Analysis/033121MortalityBestMultReg12to13.csv"), read.csv)

##Mortality data
MortData <- IndivCond_final(sitesdata, sites)

##Growth Rate and Dieback Data
GrDbkData <- IndivHeights_byTree(sitesdata, years, sites)
#GrDbkData <- PercGrowth_byTree(sitesdata, years, sites)

functype <- c("E", "L", "Q", "Q", "Q", "Q", "Q", "Q", "Q")
```


## Cross-validation

You have the infrastructure in place to do a lot of it, but you need some kind of cross-validation between the ones within 2 AIC values
- so rather than getting the in-depth info for those, get the top ones, then do cross-validation

10-fold cross-validation?


May consider using MAE instead of RMSE: https://medium.com/usf-msds/choosing-the-right-metric-for-machine-learning-models-part-1-a99d7d7414e4


p1 <- predict(res1_obj,Test_df, re.form=NA, type = "response")
p0 <- predict(res1_obj, Test_df, type = "response")

brier score - https://en.wikipedia.org/wiki/Brier_score

```{r}

###Skeleton cross-validation - using caret package

##Phenology first to test it - it is simpler 
###you want to try to stratify by family though (or at least by Source)

d_vars <- c("Phenology", "TotGrowth", "AmntDieback", "PercDead")
#d_vars <- c("TotGrowth", "AmntDieback", "PercDead")
Phen_types <- c("Bud.Swollen", "Bud.Elongating", "Leaves.emerging")
dvar <- 0 #just to keep track of whcih one you're on 
k_fold <- 5

for (DepVar in regdata) { #For each response variable 
  dvar <- dvar + 1
  
  if (dvar ==1){
      #just for right now since you should already have phenology
      ##how many groups (variables) there are
      n <- 3
      ##set up the dataframe and grouping variable 
      df <- PhenData
      df <- df[complete.cases(df), ] #get rid of the NAs basically
      df_class <- df$Name
      RandVar <- match("Block", colnames(df)) #random variable
      
      ##Create training and test datasets
      folds <- createFolds(df_class, list = FALSE, k = k_fold)
      
      paramlist <- c("Ecoregion", "Lat", "Long", "Elev", "eFFP", 
               "MSP", "Slope", "Aspect", "DD.5.sp")
      #next #just for now
      
    } else if (dvar == 2 || dvar == 3 || dvar == 4){
      n <- 4 #the number of sites for Growth Rate, Dieback, and Mortality 
      
      paramlist <- c("Ecoregion", "Dist", "Slope", "Aspect", "ElevDist", "eFFP", "MSP", "DD.5.sp")
      
    } 
  
  
  #######################################################################
  for (grp in 1:n){ ##the groupings, either by site or by phen for phenology 
    
    ##MAE list
    mae_vals <- c()
    
    if (dvar == 1) { ##Phenology
      grp_col <- grp + 9
      grp_nm <- Phen_types[grp] 
      pert_regs <- DepVar[DepVar$Phen == grp_nm,]
      ntrials = NA
      f = "linear"
      
    } else if (dvar == 2 || dvar == 3){ #growth rate or dieback
      grp_nm <- names(GrDbkData)[grp]
      
      df <- GrDbkData[[grp]]
      df <- df[complete.cases(df), ] #get rid of the NAs basically
      df_class <- df$Source
      binomial = FALSE
        
      folds <- createFolds(df_class, list = FALSE, k = k_fold)
      
      if (dvar == 2){
        grp_col <- match("TotGrowth", colnames(df)) 
        RandVar <- match("Block", colnames(df)) #random variable
        f = "linear"
        
      } else {
        
        grp_col <- match("AmntDieback", colnames(df))
        RandVar <- match("Block", colnames(df)) #random variable
        f = "zeroinfl"
      
      }
      
      pert_regs <- DepVar[(DepVar$Site == grp_nm),] #find the regressions for that site
      
    } else if (dvar == 4){ #Mortality 
      grp_nm <- names(MortData)[grp]
      
      df <- MortData[[grp]]
      df <- df[complete.cases(df), ] #get rid of the NAs basically
      df_class <- df$Source
      binomial = TRUE
      
      folds <- createFolds(df_class, list = FALSE, k = k_fold)
      
      grp_col <- match("PercDead", colnames(df)) 
      RandVar <- match("Block", colnames(df)) #random variable
      ntrials <- match("Total", colnames(df))
      
      pert_regs <- DepVar[(DepVar$Site == grp_nm),] #find the regressions for that site
      
      f = "binomial"
      
    } ## end of training dataset deliniation loop 
  

    ######################################################################
    for (k in 1:k_fold){ 
    
      ##Initialize parameter lists
      Train <- df[(folds!=k),]
      Test  <- df[(folds==k),]
      
      reg_mae <- c()
      
      for (reg in 1:length(pert_regs[,1])){ #For each regression
      
        indep_vars <- unlist(strsplit(pert_regs$IndepVars[reg], "_")) #split the variables up 
        indep_ind <- match(indep_vars, colnames(df)) #get the indexes for the independent variables
        indep_func_ind <- match(indep_vars, paramlist) #get the index for their function types
      
        
        if (dvar ==1|| dvar==4){ ##for the phenology data
        
          reg_res1 <- MultReg3(Train, indep_ind, grp_col, RandVar, family = f, priorw = ntrials)
          #reg_results
          
          res1_df <- reg_res1[[1]]
          res1_obj <- reg_res1[[2]]
          
          
          ##should be able to use the function predict, but you have to create the right format of df
          Test_df <- as.data.frame(matrix(0, nrow = length(Test[,1]), ncol = length(res1_df)))
          names(Test_df) <- names(res1_df)

          if (dvar == 4){
            for (c in 1:length(res1_df)){
              
              if (c == 1){
                Test_df[,c] <- Test[,grp_col] #Dependent Variable
                
              } else if (c != length (res1_df)){
                
                if( c == (length(res1_df)-1)){
                  Test_df[,c] <- Test[,RandVar] #Random Variable
                } else {
                  Test_df[,c] <- Test[,indep_ind[(c-1)]] #Independent Variables
                }
                
              } else {
                Test_df[,c] <- Test[,ntrials]
              }
            }
          } else {
            for (c in 1:length(res1_df)){
              
              if (c == 1){
                Test_df[,c] <- Test[,grp_col] #Dependent Variable
                
              } else if (c != length (res1_df)){
              
                Test_df[,c] <- Test[,indep_ind[(c-1)]] #Independent Variables
                
              } else {
                Test_df[,c] <- Test[,RandVar] #Random Variable
              }
            }
            
          }
          
          
          if (dvar==4 && (length(Test_df[1,]) > 4)){ #to deal with the rescaling that you have to do
            
            toRescale <- Test_df[,!(names(Test_df) %in% c("dep_dat", "rand1_dat", "ntrials"))]
    
            numcols <- c(1:length(toRescale[1,]))[sapply(toRescale[1,], is.numeric)]
            toRescale[,numcols] <- scale(toRescale[,numcols])
            
            Test_df[,!(names(Test_df) %in% c("dep_dat", "rand1_dat", "ntrials"))] <- toRescale
          }
          
          predictions <- res1_obj %>% predict(Test_df, type = "response")  #predict(res1_obj, Test_df)
          
          if (dvar == 1){
             
            #mae_v <- RMSE(as.vector(predictions), Test[,grp_col]) 
            mae_v <- MAE(as.vector(predictions), Test[,grp_col])
          } else {
            #mae_v <- RMSE(Test[,grp_col],as.vector(predictions))
            mae_v <- MAE(as.vector(predictions), Test[,grp_col])
          }
          
          
        } else { ##for everything except the Phenology ones
          types <- functype[indep_func_ind] #get the function types
          
          ##Add the names of/number of independent variables to the corresponding lists
     
          reg_res1 <- MultReg2(Train, indep_ind, grp_col, types, RandVar, family = f)
          
          res1_df <- reg_res1[[1]]
          res1_obj <- reg_res1[[2]]
          
          ##should be able to use the function predict, but you have to create the right format of df
          Test_df <- as.data.frame(matrix(0, nrow = length(Test[,1]), ncol = length(res1_df)))
          names(Test_df) <- names(res1_df)
          
          sq <- FALSE
          test_ind <- 1
  
          for (c in 1:length(res1_df)){
            
            if (c == 1){
              Test_df[,c] <- Test[,grp_col] #Dependent Variable
              
            } else if (c == length(res1_df)) {
              
              Test_df[,c] <- Test[,RandVar] #Random Variable
              
            } else if (types[test_ind] == "E" || types[test_ind] == "L") {
              Test_df[,c] <- Test[,indep_ind[(c-1)]] #Independent Variables
              test_ind <- test_ind + 1
              
            } else { #not at the end and not a linear term (so the quadratic terms)
              
              if (sq) { #if it is the square of a value
                
                Test_df[,c] <- (Test[,indep_ind[(test_ind)]])^2 #Independent Variable Squared
                sq <- FALSE
                
                if (test_ind < length(types)){
                  test_ind <- test_ind + 1
                }
                
                } else {
                Test_df[,c] <- Test[,indep_ind[(test_ind)]] #Independent Variables
                sq <- TRUE
              }
              
            }
            
          }
            
            predictions <- predict(res1_obj, Test_df)
            mae_v <- MAE(as.vector(predictions), Test[,grp_col])
            #mae_v <- RMSE(as.vector(predictions), Test[,grp_col])
        } #end of gr, dbk, mort if statement
        
        reg_mae <- append(reg_mae, mae_v)
          
      } #End of regression for loop

      mae_vals[[k]] <- reg_mae
            
        
    } ## end of cross-val loop

    if (grp==1){ ###############################################Need to make sure this is in the right place
    
      #Overall Model Matrix
      nrowsOverall = length(mae_vals[[1]])
      
      o_cols <- c("Group", "Dep", "Indep", print(paste("MAE", 1:k, sep="")))
      overal_mod <- as.data.frame(matrix(NA, nrow = nrowsOverall, ncol = length(o_cols)))
      colnames(overal_mod) <- o_cols
      
      overal_mod[,1] <- rep(grp_nm, length(nrowsOverall))
      overal_mod[,2] <- rep(d_vars[dvar], nrowsOverall)
      overal_mod[,3] <- pert_regs[, 3]
      
      #To assign the error columns in a visible way/easy to summarize 
      for (error_col in 1:k){
        overal_mod[,(error_col+3)] <- mae_vals[[error_col]]
      }
      
      
    } else { #depending on which Phenological Var you're on
      
      nrowsOverall = length(pert_regs[,1]) + length(overal_mod[,1])
      nrows_nw <- length(pert_regs[,1])
      oldOveralmat = overal_mod
      
      o_cols <- c("Group", "Dep", "Indep", print(paste("MAE", 1:k, sep="")))
      overal_mod <- matrix(NA, nrow = nrowsOverall, ncol = length(o_cols))
      colnames(overal_mod) <- o_cols
      
      overal_mod[,1] <- append(oldOveralmat[,1], rep(grp_nm, nrows_nw))
      overal_mod[,2] <- append(oldOveralmat[,2], rep(d_vars[dvar], nrows_nw))
      overal_mod[,3] <- append(oldOveralmat[,3], pert_regs[, 3])
      
      #To assign the error columns in a visible way/easy to summarize 
      for (error_col in 1:k){
        overal_mod[,(error_col+3)] <- append(oldOveralmat[,(error_col+3)], mae_vals[[error_col]])
      }
      
    } #depending on which group loop you're on 

  } ## end of site/phenological loop 
  
  write.csv(overal_mod, print(paste(d_vars[dvar], "_040221_MAE14to15.csv", sep="")))
  
}  




```

##Correlations between Independent Variables
```{r}

#c("Ecoregion", "Dist", "Slope", "Aspect", "ElevDist", "eFFP", "MSP")

# ##For GR, Mort, and DBK
# for (st in sitesdata){
#   
#   param1_list <- c("Distance", "Slope", "Aspect", "ElevDist", "eFFP", "MSP")
#   param2_list <- param1_list
#   
#   for (param1 in param1_list){
#     p1_ind <- match(param1, names(st))
#     
#     rem <- match(param1, param2_list)
#     param2_list <- param2_list[-rem]
#     
#     for (param2 in param2_list){
#       
#       p2_ind <- match(param2, names(st))
#       corr <- cor.test(st[,p1_ind], st[,p2_ind], method="pearson")
# 
#       
#       print(paste("Correlation between ", param1, " and ", param2, " at ",st$Site[1], sep=""))
#       print(corr)
#       
#       c_plot <- plot(st[,p1_ind], st[,p2_ind])
#       print(c_plot)
#     }
#     
#   }
#   
# }

# ##For Phenology
# param1_list <- c("Lat", "Long", "Slope", "Aspect", "Elev", "eFFP", "MSP")
# param2_list <- param1_list
# 
# for (param1 in param1_list){
#   p1_ind <- match(param1, names(PhenData))
#   
#   rem <- match(param1, param2_list)
#   param2_list <- param2_list[-rem]
#   
#   for (param2 in param2_list){
#     
#     p2_ind <- match(param2, names(PhenData))
#     corr <- cor.test(PhenData[,p1_ind], PhenData[,p2_ind], method="pearson")
# 
#     
#     print(paste("Correlation between ", param1, " and ", param2, " for Phenology ", sep=""))
#     print(corr)
#     
#     c_plot <- plot(PhenData[,p1_ind], PhenData[,p2_ind])
#     print(c_plot)
#   }
#   
# }



```

##Outliers Analysis

```{r}

regs <- list()
regs[[1]] <- as.data.frame(matrix(c("PH", "Ecoregion_Dist", "PV", "Ecoregion_eFFP", "SF", "Ecoregion_Dist_Aspect", "SO", "Ecoregion_Dist_eFFP"), ncol = 2, byrow=TRUE)) #growth
names(regs[[1]]) <- c("Site", "IndepVars")
regs[[2]] <- as.data.frame(matrix(c("PH", "Ecoregion_ElevDist", "PV", "Ecoregion_Dist_Slope_ElevDist_eFFP", "SF", "Ecoregion_Dist_Slope", "SO", "Ecoregion_Dist_Slope_MSP"),  ncol = 2, byrow=TRUE)) #mortality
names(regs[[2]]) <- c("Site", "IndepVars")

sites <- c("PV", "PH", "SF", "SO")

d_vars <- c("TotGrowth", "PercDead")
dvar <- 0 #just to keep track of whcih one you're on 
k_fold <- 2

##outlier storage
outlier_mat <- as.data.frame(matrix(0, nrow = 160, ncol=6))
names(outlier_mat) <- c("DepVar", "Site", "Family", "Type", "Perc", "Tot")

Omat_ind <- 0

##Actual Loop
for (DepVar in regs) { #For each response variable 
  dvar <- dvar + 1
  n <- 4 #the number of sites for Growth Rate, Dieback, and Mortality 
      
  paramlist <- c("Ecoregion", "Dist", "Slope", "Aspect", "ElevDist", "eFFP", "MSP", "DD.5.sp")
      
  #######################################################################
  for (grp in 1:n){ ##the groupings, either by site or by phen for phenology 
    
    ##MAE list
    #mae_vals <- c()
    
      
  if (dvar == 1){ #growth rate or dieback
      grp_nm <- sites[grp]
      
      df <- GrDbkData[[grp]]
      df <- df[complete.cases(df), ] #get rid of the NAs basically
      df_class <- df$Source
      binomial = FALSE
        
      folds <- createFolds(df_class, list = FALSE, k = k_fold)
      
      ##THIS NEEDS TO BE CHANGED
      pert_regs <- DepVar[(DepVar$Site == grp_nm),] #find the regressions for that site
      
      
      grp_col <- match("TotGrowth", colnames(df)) 
      RandVar <- match("Block", colnames(df)) #random variable
      
      dvar_nm <- "Growth"
      
    } else if (dvar == 2){ #Mortality 
      grp_nm <- sites[grp]
      
      df <- MortData[[grp]]
      df <- df[complete.cases(df), ] #get rid of the NAs basically
      df_class <- df$Source
      binomial = TRUE
      
      folds <- createFolds(df_class, list = FALSE, k = k_fold)
      
      grp_col <- match("PercDead", colnames(df)) 
      RandVar <- match("Block", colnames(df)) #random variable
      ntrials <- match("Total", colnames(df))
      
      pert_regs <- DepVar[(DepVar$Site == grp_nm),] #find the regressions for that site
      
      dvar_nm <- "Mortality"
      
    } ## end of training dataset deliniation loop 
  

    ######################################################################
    for (k in 2:k_fold){ 
    
      ##Initialize parameter lists
      Train <- df[(folds!=k),]
      Test  <- df[(folds==k),]
      
      reg_mae <- c()
      
      
        indep_vars <- unlist(strsplit(pert_regs$IndepVars[1], "_")) #split the variables up 
        indep_ind <- match(indep_vars, colnames(df)) #get the indexes for the independent variables
        indep_func_ind <- match(indep_vars, paramlist) #get the index for their function types
      
        
        if (dvar ==2){ ##for the mortality data
        
          reg_res1 <- MultReg3(Train, indep_ind, grp_col, RandVar, binomial, priorw = ntrials)
          #reg_results
          
          res1_df <- reg_res1[[1]]
          res1_obj <- reg_res1[[2]]
          
          
          ##should be able to use the function predict, but you have to create the right format of df
          Test_df <- as.data.frame(matrix(0, nrow = length(Test[,1]), ncol = length(res1_df)))
          names(Test_df) <- names(res1_df)

          for (c in 1:length(res1_df)){
            
            if (c == 1){
              Test_df[,c] <- Test[,grp_col] #Dependent Variable
              
            } else if (c != length (res1_df)){
              
              if( c == (length(res1_df)-1)){
                Test_df[,c] <- Test[,RandVar] #Random Variable
              } else {
                Test_df[,c] <- Test[,indep_ind[(c-1)]] #Independent Variables
              }
              
            } else {
              Test_df[,c] <- Test[,ntrials]
            }
          }
          
          if (length(Test_df[1,]) > 4){ #to deal with the rescaling that you have to do
            
            toRescale <- Test_df[,!(names(Test_df) %in% c("dep_dat", "rand1_dat", "ntrials"))]
    
            numcols <- c(1:length(toRescale[1,]))[sapply(toRescale[1,], is.numeric)]
            toRescale[,numcols] <- scale(toRescale[,numcols])
            
            Test_df[,!(names(Test_df) %in% c("dep_dat", "rand1_dat", "ntrials"))] <- toRescale
          }
          
          predictions <- res1_obj %>% predict(Test_df, type = "response")  #predict(res1_obj, Test_df)

          err <- as.vector(predictions) - Test_df$dep_dat
          med_err <- median(err)
          err_range <- 1.5*IQR(err)
          outliers_hi <- Test$Family[err > (med_err + err_range)]
          outliers_lo <- Test$Family[err < (med_err - err_range)]
          
          
          ##turn this into some kind of percentage
          for (out in unique(outliers_hi)){ #high outliers
            Omat_ind <- Omat_ind + 1
            tot <- sum(Test$Family == out)
            o <- sum(outliers_hi == out)
            perc <- o/tot

            outlier_mat$DepVar[Omat_ind] <- dvar_nm
            outlier_mat$Site[Omat_ind] <- sites[grp]
            outlier_mat$Family[Omat_ind] <- out
            outlier_mat$Perc[Omat_ind] <- perc
            outlier_mat$Type[Omat_ind] <- "High"
            outlier_mat$Tot[Omat_ind] <- tot
          }
          
          for (out in unique(outliers_lo)){ #low outliers
            Omat_ind <- Omat_ind + 1
            tot <- sum(Test$Family == out)
            o <- sum(outliers_lo == out)
            perc <- o/tot
            
            outlier_mat$DepVar[Omat_ind] <- dvar_nm
            outlier_mat$Site[Omat_ind] <- sites[grp]
            outlier_mat$Family[Omat_ind] <- out
            outlier_mat$Perc[Omat_ind] <- perc
            outlier_mat$Type[Omat_ind] <- "Low"
            outlier_mat$Tot[Omat_ind] <- tot
            
          } #outlier low
          
          
          
        } else { ##for growth
          types <- functype[indep_func_ind] #get the function types
          
          ##Add the names of/number of independent variables to the corresponding lists
     
          reg_res1 <- MultReg2(Train, indep_ind, grp_col, types, RandVar)
          
          res1_df <- reg_res1[[1]]
          res1_obj <- reg_res1[[2]]
          
          ##should be able to use the function predict, but you have to create the right format of df
          Test_df <- as.data.frame(matrix(0, nrow = length(Test[,1]), ncol = length(res1_df)))
          names(Test_df) <- names(res1_df)
          
          sq <- FALSE
          test_ind <- 1
  
          for (c in 1:length(res1_df)){
            
            if (c == 1){
              Test_df[,c] <- Test[,grp_col] #Dependent Variable
              
            } else if (c == length(res1_df)) {
              
              Test_df[,c] <- Test[,RandVar] #Random Variable
              
            } else if (types[test_ind] == "E" || types[test_ind] == "L") {
              Test_df[,c] <- Test[,indep_ind[(c-1)]] #Independent Variables
              test_ind <- test_ind + 1
              
            } else { #not at the end and not a linear term (so the quadratic terms)
              
              if (sq) { #if it is the square of a value
                
                Test_df[,c] <- (Test[,indep_ind[(test_ind)]])^2 #Independent Variable Squared
                sq <- FALSE
                
                if (test_ind < length(types)){
                  test_ind <- test_ind + 1
                }
                
                } else {
                Test_df[,c] <- Test[,indep_ind[(test_ind)]] #Independent Variables
                sq <- TRUE
              }
              
            }
            
          } #create the test df
            
          predictions <- predict(res1_obj, Test_df)
          err <- as.vector(predictions) - Test_df$dep_dat
          med_err <- median(err)
          err_range <- 1.5*IQR(err)
          outliers_hi <- Test$Family[err > (med_err + err_range)]
          outliers_lo <- Test$Family[err < (med_err - err_range)]
          
          
          ##turn this into some kind of percentage
          for (out in unique(outliers_hi)){ #high outliers
            Omat_ind <- Omat_ind + 1
            tot <- sum(Test$Family == out)
            o <- sum(outliers_hi == out)
            perc <- o/tot

            outlier_mat$DepVar[Omat_ind] <- dvar_nm
            outlier_mat$Site[Omat_ind] <- sites[grp]
            outlier_mat$Family[Omat_ind] <- out
            outlier_mat$Perc[Omat_ind] <- perc
            outlier_mat$Type[Omat_ind] <- "High"
            outlier_mat$Tot[Omat_ind] <- tot
            
          }
          
          for (out in unique(outliers_lo)){ #low outliers
            Omat_ind <- Omat_ind + 1
            tot <- sum(Test$Family == out)
            o <- sum(outliers_lo == out)
            perc <- o/tot
            
            outlier_mat$DepVar[Omat_ind] <- dvar_nm
            outlier_mat$Site[Omat_ind] <- sites[grp]
            outlier_mat$Family[Omat_ind] <- out
            outlier_mat$Perc[Omat_ind] <- perc
            outlier_mat$Type[Omat_ind] <- "Low"
            outlier_mat$Tot[Omat_ind] <- tot
            
          } #outlier low
            
            
            
        } #end of gr mort if statement
        
        #reg_mae <- append(reg_mae, mae_v)
          
      } ## end of cross-val loop
      
    } #depending on which group loop you're on 
  
}

write.csv(outlier_mat, print(paste("outliers_033121_NOTSPLIT.csv", sep="")))

```


##Just consistently high and low?

How do you decide this though? From the mean? From the median? mean plus minus 1.5*iqr? Just trace individual families and do it more ad hoc?

Maybe just plot the families and go from there? You're going to get the pushback that it's not "objective". Go back to the percentages maybe? Take the top and bottom 10%? 

```{r}
##Mortality data (MortData)



##Growth Rate and Dieback Data (GrDbkData)

```

